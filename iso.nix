{ config, pkgs, lib, ... }:

{
  # ZFS Support
  boot.supportedFilesystems = [ "zfs" ];
  boot.zfs.forceImportRoot = false; # Don't auto-import on boot to avoid conflicts, let user/scripts do it
  networking.hostId = "8425e349"; # Required for ZFS, using a random fixed ID

  # Kernel & Hardware
  boot.kernelPackages = pkgs.linuxPackages_latest;
  
  # Hypervisor & Virtualization
  virtualisation.libvirtd = {
    enable = true;
    qemu = {
      package = pkgs.qemu_kvm;
      runAsRoot = false;
      swtpm.enable = true;
      ovmf.enable = true;
    };
  };

  # Cockpit Management
  services.cockpit = {
    enable = true;
    openFirewall = true;
    settings = {
      WebService = {
        AllowUnencrypted = true;
      };
    };
  };
  
  # Add cockpit-machines for VM management
  environment.systemPackages = with pkgs; [
    cockpit
    cockpit-machines
    # cockpit-zfs-manager # Not in standard nixpkgs, relying on CLI
    zfs
    parted
    gptfdisk
    htop
    vim
    git
    pciutils
    usbutils
    smartmontools
    nvme-cli
    os-prober
    efibootmgr
    
    (pkgs.writeShellScriptBin "import-proxmox-pools" ''
      #!/bin/sh
      echo "Scanning for ZFS pools..."
      sudo zpool import
      
      echo ""
      echo "To import a pool, run: sudo zpool import -f <poolname>"
      echo "The -f flag is often needed if the pool was not cleanly exported (e.g. crash/power loss)."
      echo "Proxmox pools are typically named 'rpool'."
    '')
  ];

  # Networking
  networking.networkmanager.enable = true;
  networking.firewall.enable = false; # For a rescue/hypervisor ISO, easier to allow all initially

  # User Configuration
  users.users.root.password = "nixos"; # Default password for the ISO
  services.openssh = {
    enable = true;
    settings.PermitRootLogin = "yes";
  };

  # ISO Specifics
  isoImage.squashfsCompression = "zstd";
  
  # Serial console support for headless management
  boot.kernelParams = [ "console=ttyS0,115200" "console=tty0" ];
  
  # Bootloader tweaks to help with booting other drives
  # The standard install-iso uses systemd-boot (UEFI) and syslinux (BIOS)
  # We enable os-prober to help detect other OSes if we were installing, 
  # but for the ISO boot menu itself, it's generated by the build process.
  # We can add a hook to scan for pools on login.
  
  systemd.services.zfs-import-scan = {
    description = "Scan for ZFS pools (optional auto-import)";
    after = [ "zfs-import.target" ];
    serviceConfig = {
      Type = "oneshot";
      ExecStart = "${pkgs.zfs}/bin/zpool import"; # Just list them to log
      RemainAfterExit = true;
    };
  };
}
